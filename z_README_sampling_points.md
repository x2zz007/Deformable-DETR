# Deformable DETR ä¸­çš„é‡‡æ ·ç‚¹(Sampling Points)è¯¦è§£

## ç®€ä»‹

åœ¨Deformable DETRä¸­ï¼Œ**é‡‡æ ·ç‚¹(Sampling Points)**æ˜¯MS-Deformable Attentionçš„æ ¸å¿ƒã€‚

**æ ¸å¿ƒæ€æƒ³**: ä¸æ˜¯åœ¨å‚è€ƒç‚¹å¤„é‡‡æ ·ï¼Œè€Œæ˜¯åœ¨å‚è€ƒç‚¹**å‘¨å›´**é‡‡æ ·å¤šä¸ªç‚¹ï¼Œç„¶ååŠ æƒèåˆã€‚

å¯ä»¥æŠŠé‡‡æ ·ç‚¹æƒ³è±¡æˆï¼š**åœ¨å‚è€ƒç‚¹å‘¨å›´æ”¾ç½®å¤šä¸ª"æ¢é’ˆ"ï¼Œä»è¿™äº›ä½ç½®æ”¶é›†ä¿¡æ¯**ã€‚

---

## 1. é‡‡æ ·ç‚¹çš„åŸºæœ¬æ¦‚å¿µ

### 1.1 ç”Ÿæ´»ç±»æ¯”

æƒ³è±¡ä½ è¦äº†è§£ä¸€ä¸ªåŸå¸‚çš„æƒ…å†µï¼š

```
æ–¹æ¡ˆ1 (æ ‡å‡†Attention): åªåœ¨å¸‚ä¸­å¿ƒé‡‡æ ·
  â”œâ”€ ä¼˜ç‚¹: å¿«é€Ÿ
  â””â”€ ç¼ºç‚¹: ä¿¡æ¯ä¸å…¨ï¼Œå®¹æ˜“æ¼æ‰å‘¨è¾¹é‡è¦ä¿¡æ¯

æ–¹æ¡ˆ2 (Deformable Attention): åœ¨å¸‚ä¸­å¿ƒå‘¨å›´é‡‡æ ·å¤šä¸ªç‚¹
  â”œâ”€ å¸‚ä¸­å¿ƒ (å‚è€ƒç‚¹)
  â”œâ”€ å‘¨å›´8ä¸ªæ–¹å‘å„é‡‡æ ·1ä¸ªç‚¹ (é‡‡æ ·ç‚¹)
  â”œâ”€ ä¼˜ç‚¹: ä¿¡æ¯å®Œæ•´ï¼Œèƒ½çœ‹åˆ°å‘¨è¾¹æƒ…å†µ
  â””â”€ ç¼ºç‚¹: é‡‡æ ·ç‚¹æ•°å¢åŠ ï¼Œä½†ä»æ¯”å…¨å±€é‡‡æ ·å¿«å¾—å¤š
```

### 1.2 æ•°å­¦è¡¨ç¤º

**å‚è€ƒç‚¹** vs **é‡‡æ ·ç‚¹**:

```
å‚è€ƒç‚¹ (Reference Point):
  p_ref = (x_ref, y_ref)  â† ä¸€ä¸ªç‚¹

é‡‡æ ·ç‚¹ (Sampling Points):
  p_sample_i = p_ref + Î”p_i  â† å¤šä¸ªç‚¹

å…¶ä¸­ Î”p_i æ˜¯ç¬¬iä¸ªé‡‡æ ·ç‚¹ç›¸å¯¹äºå‚è€ƒç‚¹çš„åç§»
```

**å…·ä½“ä¾‹å­**:

```
å‚è€ƒç‚¹: (0.5, 0.5)

é‡‡æ ·ç‚¹1: (0.5, 0.5) + (-0.1, -0.1) = (0.4, 0.4)  â† å·¦ä¸Š
é‡‡æ ·ç‚¹2: (0.5, 0.5) + (0.0, -0.1)  = (0.5, 0.4)  â† ä¸Š
é‡‡æ ·ç‚¹3: (0.5, 0.5) + (0.1, -0.1)  = (0.6, 0.4)  â† å³ä¸Š
é‡‡æ ·ç‚¹4: (0.5, 0.5) + (-0.1, 0.0)  = (0.4, 0.5)  â† å·¦
é‡‡æ ·ç‚¹5: (0.5, 0.5) + (0.1, 0.0)   = (0.6, 0.5)  â† å³
é‡‡æ ·ç‚¹6: (0.5, 0.5) + (-0.1, 0.1)  = (0.4, 0.6)  â† å·¦ä¸‹
é‡‡æ ·ç‚¹7: (0.5, 0.5) + (0.0, 0.1)   = (0.5, 0.6)  â† ä¸‹
é‡‡æ ·ç‚¹8: (0.5, 0.5) + (0.1, 0.1)   = (0.6, 0.6)  â† å³ä¸‹

ç”¨å›¾è¡¨ç¤º:
  â—  â—  â—
  â—  â—  â—
  â—  â—  â—
```

---

## 2. é‡‡æ ·ç‚¹çš„å®Œæ•´è·å–æµç¨‹

### 2.1 æµç¨‹æ¦‚è§ˆ

```
è¾“å…¥: æŸ¥è¯¢å‘é‡ query (bs, 300, 256)
  â”‚
  â”œâ”€ å‚è€ƒç‚¹ reference_points (bs, 300, 4, 2)
  â”‚
  â–¼
ç¬¬1æ­¥: è®¡ç®—é‡‡æ ·åç§» Î”p
  â”‚ Linear(256 â†’ 256)
  â”‚ è¾“å‡º: (bs, 300, 8, 4, 4, 2)
  â”‚
  â–¼
ç¬¬2æ­¥: è®¡ç®—æ³¨æ„åŠ›æƒé‡ Î±
  â”‚ Linear(256 â†’ 128) + Softmax
  â”‚ è¾“å‡º: (bs, 300, 8, 4, 4)
  â”‚
  â–¼
ç¬¬3æ­¥: è®¡ç®—é‡‡æ ·ä½ç½® p_sample
  â”‚ p_sample = p_ref + Î”p / offset_normalizer
  â”‚ è¾“å‡º: (bs, 300, 8, 4, 4, 2)
  â”‚
  â–¼
ç¬¬4æ­¥: åŒçº¿æ€§æ’å€¼é‡‡æ ·
  â”‚ ä»ç‰¹å¾å›¾é‡‡æ ·ç‰¹å¾å€¼
  â”‚ è¾“å‡º: (bs, 300, 8, 4, 4, 32)
  â”‚
  â–¼
ç¬¬5æ­¥: åŠ æƒèåˆ
  â”‚ output = âˆ‘âˆ‘ Î± * v_sample
  â”‚ è¾“å‡º: (bs, 300, 256)
  â”‚
  â–¼
è¾“å‡º: æœ€ç»ˆç‰¹å¾ (bs, 300, 256)
```

### 2.2 å…³é”®å‚æ•°è¯´æ˜

```
bs = batch_size = 2          (ä¸€æ¬¡å¤„ç†2å¼ å›¾)
300 = num_queries            (300ä¸ªæŸ¥è¯¢/ç›®æ ‡)
256 = d_model                (ç‰¹å¾ç»´åº¦)

8 = n_heads                  (8ä¸ªæ³¨æ„åŠ›å¤´)
4 = n_levels                 (4ä¸ªç‰¹å¾å±‚)
4 = n_points                 (æ¯å±‚4ä¸ªé‡‡æ ·ç‚¹)

æ€»é‡‡æ ·ç‚¹æ•° = 8 Ã— 4 Ã— 4 = 128 ä¸ªé‡‡æ ·ç‚¹ï¼
```

---

## 3. é‡‡æ ·åç§»(Sampling Offsets)è¯¦è§£

### 3.1 ä»€ä¹ˆæ˜¯é‡‡æ ·åç§»ï¼Ÿ

**é‡‡æ ·åç§»** = ä»å‚è€ƒç‚¹åˆ°é‡‡æ ·ç‚¹çš„**ç›¸å¯¹ä½ç§»**

```
é‡‡æ ·åç§» Î”p = é‡‡æ ·ç‚¹ - å‚è€ƒç‚¹

ä¾‹å¦‚:
  å‚è€ƒç‚¹: (0.5, 0.5)
  é‡‡æ ·ç‚¹: (0.6, 0.4)
  é‡‡æ ·åç§»: (0.6 - 0.5, 0.4 - 0.5) = (0.1, -0.1)
```

**æ•°å­¦å…¬å¼**:

$$\Delta p_i = p_{\text{sample},i} - p_{\text{ref}}$$

### 3.2 é‡‡æ ·åç§»çš„åˆå§‹åŒ–

åœ¨Deformable DETRä¸­ï¼Œé‡‡æ ·åç§»æœ‰ä¸€ä¸ª**å·§å¦™çš„åˆå§‹åŒ–æ–¹å¼**ï¼š

```python
# ä»£ç ä½ç½®: models/ops/modules/ms_deform_attn.py ç¬¬62-72è¡Œ

def _reset_parameters(self):
    # ç¬¬1æ­¥: é‡‡æ ·åç§»æƒé‡åˆå§‹åŒ–ä¸º0
    constant_(self.sampling_offsets.weight.data, 0.)

    # ç¬¬2æ­¥: ç”Ÿæˆå•ä½åœ†ä¸Šå‡åŒ€åˆ†å¸ƒçš„ç‚¹
    thetas = torch.arange(self.n_heads, dtype=torch.float32) * (2.0 * math.pi / self.n_heads)
    # n_heads = 8
    # thetas = [0, Ï€/4, Ï€/2, 3Ï€/4, Ï€, 5Ï€/4, 3Ï€/2, 7Ï€/4]

    grid_init = torch.stack([thetas.cos(), thetas.sin()], -1)
    # ç”Ÿæˆå•ä½åœ†ä¸Šçš„8ä¸ªç‚¹

    # ç¬¬3æ­¥: é‡å¡‘ä¸º (n_heads, n_levels, n_points, 2)
    grid_init = (grid_init / grid_init.abs().max(-1, keepdim=True)[0]).view(
        self.n_heads, 1, 1, 2
    ).repeat(1, self.n_levels, self.n_points, 1)
    # å½¢çŠ¶: (8, 4, 4, 2)

    # ç¬¬4æ­¥: æŒ‰ç…§pointç´¢å¼•ç¼©æ”¾
    for i in range(self.n_points):  # n_points = 4
        grid_init[:, :, i, :] *= i + 1
        # ç¬¬1ä¸ªé‡‡æ ·ç‚¹: è·ç¦»ä¸­å¿ƒ 1 å•ä½
        # ç¬¬2ä¸ªé‡‡æ ·ç‚¹: è·ç¦»ä¸­å¿ƒ 2 å•ä½
        # ç¬¬3ä¸ªé‡‡æ ·ç‚¹: è·ç¦»ä¸­å¿ƒ 3 å•ä½
        # ç¬¬4ä¸ªé‡‡æ ·ç‚¹: è·ç¦»ä¸­å¿ƒ 4 å•ä½

    # ç¬¬5æ­¥: è®¾ç½®ä¸ºbias
    with torch.no_grad():
        self.sampling_offsets.bias = nn.Parameter(grid_init.view(-1))
```

### 3.3 åˆå§‹åŒ–çš„å¯è§†åŒ–

```
åˆå§‹åŒ–åçš„é‡‡æ ·åç§» (ä»¥ç¬¬1ä¸ªå¤´ä¸ºä¾‹):

Level 0 (æœ€ç²¾ç»†):
  é‡‡æ ·ç‚¹1: è·ç¦»ä¸­å¿ƒ 1 å•ä½ï¼Œæ–¹å‘ 0Â°   â†’ (1, 0)
  é‡‡æ ·ç‚¹2: è·ç¦»ä¸­å¿ƒ 2 å•ä½ï¼Œæ–¹å‘ 45Â°  â†’ (1.414, 1.414)
  é‡‡æ ·ç‚¹3: è·ç¦»ä¸­å¿ƒ 3 å•ä½ï¼Œæ–¹å‘ 90Â°  â†’ (0, 3)
  é‡‡æ ·ç‚¹4: è·ç¦»ä¸­å¿ƒ 4 å•ä½ï¼Œæ–¹å‘ 135Â° â†’ (-2.828, 2.828)

ç”¨å›¾è¡¨ç¤º (ä»¥Level 0ä¸ºä¾‹):

  é‡‡æ ·ç‚¹4 â—
         /
        /
       /
é‡‡æ ·ç‚¹3 â—â”€â”€â”€â”€â— å‚è€ƒç‚¹ â”€â”€â”€â”€â— é‡‡æ ·ç‚¹1
       \
        \
         \
  é‡‡æ ·ç‚¹2 â—
```

**ä¸ºä»€ä¹ˆè¿™æ ·åˆå§‹åŒ–ï¼Ÿ**

1. **æƒé‡ä¸º0**: åˆæœŸé‡‡æ ·åç§»ä¸º0ï¼Œæ‰€æœ‰é‡‡æ ·ç‚¹éƒ½åœ¨å‚è€ƒç‚¹å¤„
2. **Biasä¸ºåœ†å½¢**: é‡‡æ ·ç‚¹åˆæœŸå‡åŒ€åˆ†å¸ƒåœ¨å‚è€ƒç‚¹å‘¨å›´
3. **è·ç¦»é€’å¢**: ä¸åŒé‡‡æ ·ç‚¹è·ç¦»å‚è€ƒç‚¹çš„è·ç¦»ä¸åŒ
4. **8ä¸ªæ–¹å‘**: 8ä¸ªå¤´å¯¹åº”8ä¸ªä¸åŒæ–¹å‘ï¼Œå…¨é¢è¦†ç›–


---

## 4. æ³¨æ„åŠ›æƒé‡(Attention Weights)è¯¦è§£

### 4.1 ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æƒé‡ï¼Ÿ

**æ³¨æ„åŠ›æƒé‡** = æ¯ä¸ªé‡‡æ ·ç‚¹çš„**é‡è¦æ€§ç³»æ•°**

```
æ¦‚å¿µ:
  - æœ‰128ä¸ªé‡‡æ ·ç‚¹
  - ä½†å®ƒä»¬çš„é‡è¦æ€§ä¸åŒ
  - æ³¨æ„åŠ›æƒé‡å†³å®šäº†æ¯ä¸ªé‡‡æ ·ç‚¹å¯¹æœ€ç»ˆç»“æœçš„è´¡çŒ®ç¨‹åº¦

ä¾‹å¦‚:
  é‡‡æ ·ç‚¹1çš„æƒé‡: 0.3  â† é‡è¦ï¼Œè´¡çŒ®30%
  é‡‡æ ·ç‚¹2çš„æƒé‡: 0.2  â† ä¸­ç­‰ï¼Œè´¡çŒ®20%
  é‡‡æ ·ç‚¹3çš„æƒé‡: 0.1  â† ä¸é‡è¦ï¼Œè´¡çŒ®10%
  ...
  æ€»å’Œ: 1.0 (é€šè¿‡softmaxä¿è¯)
```

### 4.2 æ³¨æ„åŠ›æƒé‡çš„è®¡ç®—

```python
# ä»£ç ä½ç½®: models/ops/modules/ms_deform_attn.py ç¬¬99-100è¡Œ

def forward(self, query, reference_points, input_flatten, ...):
    # ç¬¬1æ­¥: é€šè¿‡çº¿æ€§å±‚è®¡ç®—åŸå§‹æƒé‡
    attention_weights = self.attention_weights(query)
    # è¾“å…¥: query (bs, 300, 256)
    # çº¿æ€§å±‚: Linear(256 â†’ n_heads * n_levels * n_points)
    #                    = 8 * 4 * 4 = 128
    # è¾“å‡º: (bs, 300, 128)

    # ç¬¬2æ­¥: é‡å¡‘ä¸ºå¤šç»´å¼ é‡
    attention_weights = attention_weights.view(
        N, Len_q, self.n_heads, self.n_levels * self.n_points
    )
    # è¾“å‡º: (bs, 300, 8, 16)

    # ç¬¬3æ­¥: Softmaxæ¿€æ´»
    attention_weights = F.softmax(attention_weights, -1)
    # åœ¨æœ€åä¸€ç»´(16)ä¸Šè¿›è¡Œsoftmax
    # ä¿è¯æ¯ä¸ªå¤´çš„16ä¸ªæƒé‡(4å±‚Ã—4ç‚¹)ä¹‹å’Œä¸º1

    # ç¬¬4æ­¥: é‡å¡‘ä¸ºæœ€ç»ˆå½¢çŠ¶
    attention_weights = attention_weights.view(
        N, Len_q, self.n_heads, self.n_levels, self.n_points
    )
    # è¾“å‡º: (bs, 300, 8, 4, 4)
    # å«ä¹‰: (batch, query, heads, levels, points)
```

**æ•°å­¦è¡¨ç¤º**:

$$\alpha = \text{softmax}(\text{Linear}_{\text{attn}}(q))$$

å…¶ä¸­:
- $q$ æ˜¯æŸ¥è¯¢å‘é‡
- $\text{Linear}_{\text{attn}}$ æ˜¯çº¿æ€§å±‚ï¼Œè¾“å‡ºç»´åº¦ $n_h \times n_l \times n_p$
- $\alpha$ æ˜¯æ³¨æ„åŠ›æƒé‡ï¼Œæ»¡è¶³ $\sum \alpha = 1$

### 4.3 Softmaxçš„ä½œç”¨

```
åŸå§‹æƒé‡ (æœªæ¿€æ´»):
  [0.5, -0.3, 0.2, 0.1, ...]

Softmaxå:
  [0.35, 0.08, 0.25, 0.18, ...]

æ€§è´¨:
  1. æ‰€æœ‰æƒé‡éƒ½åœ¨ (0, 1) èŒƒå›´å†…
  2. æ‰€æœ‰æƒé‡ä¹‹å’Œä¸º 1
  3. æƒé‡è¶Šå¤§ï¼Œå¯¹åº”é‡‡æ ·ç‚¹è¶Šé‡è¦
```

---

## 5. é‡‡æ ·ä½ç½®(Sampling Locations)è¯¦è§£

### 5.1 é‡‡æ ·ä½ç½®çš„è®¡ç®—å…¬å¼

**é‡‡æ ·ä½ç½®** = å‚è€ƒç‚¹ + å½’ä¸€åŒ–çš„é‡‡æ ·åç§»

```
å…¬å¼1 (å‚è€ƒç‚¹ä¸º (x, y) æ—¶):
  p_sample = p_ref + Î”p / offset_normalizer

å…¬å¼2 (å‚è€ƒç‚¹ä¸º (x, y, w, h) æ—¶):
  p_sample = p_ref[:2] + Î”p / n_points * (w, h) * 0.5
```

**æ•°å­¦è¡¨ç¤º**:

$$p_{\text{sample}} = p_{\text{ref}} + \frac{\Delta p}{\text{offset\_normalizer}}$$

### 5.2 ä»£ç å®ç°

```python
# ä»£ç ä½ç½®: models/ops/modules/ms_deform_attn.py ç¬¬102-108è¡Œ

def forward(self, query, reference_points, input_flatten, ...):
    # æƒ…å†µ1: reference_points ä¸º (x, y)
    if reference_points.shape[-1] == 2:
        offset_normalizer = torch.stack(
            [input_spatial_shapes[..., 1], input_spatial_shapes[..., 0]], -1
        )
        # è·å–æ¯ä¸ªç‰¹å¾å±‚çš„å®½å’Œé«˜: [(W0,H0), (W1,H1), ...]
        # å½¢çŠ¶: (n_levels, 2)

        sampling_locations = reference_points[:, :, None, :, None, :] \
                           + sampling_offsets / offset_normalizer[None, None, None, :, None, :]
        # reference_points: (bs, 300, 1, 4, 1, 2)  [æ‰©å±•ç»´åº¦]
        # sampling_offsets: (bs, 300, 8, 4, 4, 2)
        # offset_normalizer: (4, 2)  â†’ (1, 1, 1, 4, 1, 2)  [æ‰©å±•ç»´åº¦]
        # ç›¸é™¤æ˜¯ä¸ºäº†æ­£è§„åŒ–åˆ° [0, 1] èŒƒå›´
        # æœ€ç»ˆ: (bs, 300, 8, 4, 4, 2)

    # æƒ…å†µ2: reference_points ä¸º (x, y, w, h)
    elif reference_points.shape[-1] == 4:
        # åç§»é‡ç›¸å¯¹äºæ¡†çš„å¤§å°
        sampling_locations = reference_points[:, :, None, :, None, :2] \
                           + sampling_offsets / self.n_points * \
                             reference_points[:, :, None, :, None, 2:] * 0.5
        # reference_points[..., :2]: (x, y)
        # reference_points[..., 2:]: (w, h)
        # sampling_offsets / n_points * (w, h) * 0.5:
        #   - æŠŠåç§»é‡ç¼©æ”¾åˆ°æ¡†çš„å¤§å°èŒƒå›´
        #   - ä¹˜ä»¥0.5æ˜¯å› ä¸ºw,hä»ä¸­å¿ƒå¼€å§‹è®¡ç®—
```

### 5.3 å…·ä½“æ•°å€¼ç¤ºä¾‹

```
å‡è®¾:
  å‚è€ƒç‚¹: (0.5, 0.5)
  é‡‡æ ·åç§»: (0.1, -0.1)
  ç‰¹å¾å›¾å¤§å°: 100Ã—150
  offset_normalizer: (150, 100)  [å®½, é«˜]

è®¡ç®—:
  é‡‡æ ·ä½ç½® = (0.5, 0.5) + (0.1, -0.1) / (150, 100)
           = (0.5, 0.5) + (0.1/150, -0.1/100)
           = (0.5, 0.5) + (0.000667, -0.001)
           = (0.500667, 0.499)

ç»“æœ:
  é‡‡æ ·ä½ç½®åœ¨ [0, 1] èŒƒå›´å†…ï¼Œå¯ä»¥ç›´æ¥ç”¨äºåŒçº¿æ€§æ’å€¼
```

---

## 6. åŒçº¿æ€§æ’å€¼(Bilinear Interpolation)è¯¦è§£

### 6.1 ä»€ä¹ˆæ˜¯åŒçº¿æ€§æ’å€¼ï¼Ÿ

**é—®é¢˜**: é‡‡æ ·ä½ç½®å¯èƒ½ä¸æ˜¯æ•´æ•°åæ ‡ï¼Œå¦‚ä½•ä»ç‰¹å¾å›¾ä¸Šè·å–ç‰¹å¾å€¼ï¼Ÿ

```
ç‰¹å¾å›¾åƒç´ :
  (0, 0)  (1, 0)  (2, 0)
  (0, 1)  (1, 1)  (2, 1)
  (0, 2)  (1, 2)  (2, 2)

é‡‡æ ·ä½ç½®: (0.5, 0.5)  â† ä¸æ˜¯æ•´æ•°ï¼

è§£å†³æ–¹æ¡ˆ: ç”¨å‘¨å›´4ä¸ªåƒç´ çš„å€¼è¿›è¡ŒåŠ æƒå¹³å‡
  (0, 0) â—â”€â”€â”€â”€â”€â”€â”€â”€â— (1, 0)
         â”‚        â”‚
         â”‚ (0.5,  â”‚
         â”‚  0.5)  â”‚
         â”‚        â”‚
  (0, 1) â—â”€â”€â”€â”€â”€â”€â”€â”€â— (1, 1)
```

### 6.2 åŒçº¿æ€§æ’å€¼çš„è®¡ç®—

```
è®¾é‡‡æ ·ä½ç½®ä¸º (x, y)ï¼Œå…¶ä¸­ x, y âˆˆ [0, 1]

å‘¨å›´4ä¸ªåƒç´ çš„åæ ‡:
  (x0, y0) = (floor(x), floor(y))
  (x1, y0) = (ceil(x), floor(y))
  (x0, y1) = (floor(x), ceil(y))
  (x1, y1) = (ceil(x), ceil(y))

æƒé‡è®¡ç®—:
  w00 = (1 - (x - x0)) * (1 - (y - y0))  â† å·¦ä¸Š
  w10 = (x - x0) * (1 - (y - y0))        â† å³ä¸Š
  w01 = (1 - (x - x0)) * (y - y0)        â† å·¦ä¸‹
  w11 = (x - x0) * (y - y0)              â† å³ä¸‹

æ’å€¼ç»“æœ:
  v = w00 * v00 + w10 * v10 + w01 * v01 + w11 * v11
```

**å…·ä½“ä¾‹å­**:

```
é‡‡æ ·ä½ç½®: (0.3, 0.7)

å‘¨å›´4ä¸ªåƒç´ :
  (0, 0): å€¼=10  (1, 0): å€¼=20
  (0, 1): å€¼=30  (1, 1): å€¼=40

æƒé‡:
  w00 = (1 - 0.3) * (1 - 0.7) = 0.7 * 0.3 = 0.21
  w10 = 0.3 * (1 - 0.7) = 0.3 * 0.3 = 0.09
  w01 = (1 - 0.3) * 0.7 = 0.7 * 0.7 = 0.49
  w11 = 0.3 * 0.7 = 0.21

æ’å€¼ç»“æœ:
  v = 0.21*10 + 0.09*20 + 0.49*30 + 0.21*40
    = 2.1 + 1.8 + 14.7 + 8.4
    = 27.0
```

### 6.3 ä»£ç å®ç°

```python
# ä»£ç ä½ç½®: models/ops/functions/ms_deform_attn_func.py ç¬¬41-57è¡Œ

def ms_deform_attn_core_pytorch(value, value_spatial_shapes,
                                sampling_locations, attention_weights):
    # è¾“å…¥:
    # value: (B, âˆ‘H*W, n_heads, d_per_head)
    # sampling_locations: (B, Lq, n_heads, n_levels, n_points, 2)
    # attention_weights: (B, Lq, n_heads, n_levels, n_points)

    N_, S_, M_, D_ = value.shape
    _, Lq_, M_, L_, P_, _ = sampling_locations.shape

    # ç¬¬1æ­¥: åˆ†å‰²valueä¸ºå„ä¸ªç‰¹å¾å±‚
    value_list = value.split([H_ * W_ for H_, W_ in value_spatial_shapes], dim=1)

    # ç¬¬2æ­¥: è½¬æ¢é‡‡æ ·ä½ç½®åˆ° [-1, 1] èŒƒå›´ (grid_sampleè¦æ±‚)
    sampling_grids = 2 * sampling_locations - 1
    # ä» [0, 1] è½¬æ¢åˆ° [-1, 1]

    sampling_value_list = []
    for lid_, (H_, W_) in enumerate(value_spatial_shapes):
        # ç¬¬3æ­¥: é‡å¡‘valueä¸ºå›¾åƒæ ¼å¼
        # (B, H*W, n_heads, d_per_head) â†’ (B*n_heads, d_per_head, H, W)
        value_l_ = value_list[lid_].flatten(2).transpose(1, 2).reshape(
            N_*M_, D_, H_, W_
        )

        # ç¬¬4æ­¥: é‡å¡‘é‡‡æ ·ä½ç½®
        # (B, Lq, n_heads, n_points, 2) â†’ (B*n_heads, Lq, n_points, 2)
        sampling_grid_l_ = sampling_grids[:, :, :, lid_].transpose(1, 2).flatten(0, 1)

        # ç¬¬5æ­¥: ä½¿ç”¨grid_sampleè¿›è¡ŒåŒçº¿æ€§æ’å€¼
        sampling_value_l_ = F.grid_sample(
            value_l_,                    # (B*n_heads, d_per_head, H, W)
            sampling_grid_l_,            # (B*n_heads, Lq, n_points, 2)
            mode='bilinear',             # åŒçº¿æ€§æ’å€¼
            padding_mode='zeros',        # è¶…å‡ºè¾¹ç•Œç”¨0å¡«å……
            align_corners=False
        )
        # è¾“å‡º: (B*n_heads, d_per_head, Lq, n_points)

        sampling_value_list.append(sampling_value_l_)
```

---

## 7. åŠ æƒèåˆ(Weighted Aggregation)è¯¦è§£

### 7.1 ä»€ä¹ˆæ˜¯åŠ æƒèåˆï¼Ÿ

**åŠ æƒèåˆ** = ç”¨æ³¨æ„åŠ›æƒé‡å¯¹æ‰€æœ‰é‡‡æ ·ç‚¹çš„ç‰¹å¾è¿›è¡ŒåŠ æƒæ±‚å’Œ

```
æ¦‚å¿µ:
  - æœ‰128ä¸ªé‡‡æ ·ç‚¹ï¼Œæ¯ä¸ªéƒ½æœ‰ç‰¹å¾å€¼
  - æœ‰128ä¸ªæ³¨æ„åŠ›æƒé‡ï¼Œè¡¨ç¤ºé‡è¦æ€§
  - åŠ æƒèåˆ: é‡è¦çš„é‡‡æ ·ç‚¹è´¡çŒ®æ›´å¤šï¼Œä¸é‡è¦çš„è´¡çŒ®æ›´å°‘

å…¬å¼:
  output = âˆ‘âˆ‘ Î± * v_sample
           h l p

å…¶ä¸­:
  - h: 8ä¸ªå¤´
  - l: 4ä¸ªç‰¹å¾å±‚
  - p: 4ä¸ªé‡‡æ ·ç‚¹
  - Î±: æ³¨æ„åŠ›æƒé‡
  - v_sample: é‡‡æ ·ç‰¹å¾å€¼
```

### 7.2 åŠ æƒèåˆçš„è®¡ç®—

```python
# ä»£ç ä½ç½®: models/ops/functions/ms_deform_attn_func.py ç¬¬58-61è¡Œ

def ms_deform_attn_core_pytorch(value, value_spatial_shapes,
                                sampling_locations, attention_weights):
    # å‰é¢å·²ç»å¾—åˆ°:
    # sampling_value_list: 4ä¸ªå…ƒç´ ï¼Œæ¯ä¸ªå½¢çŠ¶ (B*n_heads, d_per_head, Lq, n_points)

    # ç¬¬1æ­¥: å †å æ‰€æœ‰ç‰¹å¾å±‚çš„é‡‡æ ·å€¼
    # (B*n_heads, d_per_head, Lq, n_levels, n_points)
    sampling_values = torch.stack(sampling_value_list, dim=-2)

    # ç¬¬2æ­¥: é‡å¡‘æ³¨æ„åŠ›æƒé‡
    # (B, Lq, n_heads, n_levels, n_points) â†’ (B*n_heads, 1, Lq, n_levels*n_points)
    attention_weights = attention_weights.transpose(1, 2).reshape(
        N_*M_, 1, Lq_, L_*P_
    )

    # ç¬¬3æ­¥: åŠ æƒæ±‚å’Œ
    # (B*n_heads, d_per_head, Lq, n_levels*n_points) * (B*n_heads, 1, Lq, n_levels*n_points)
    # â†’ (B*n_heads, d_per_head, Lq)
    output = (sampling_values.flatten(-2) * attention_weights).sum(-1)

    # ç¬¬4æ­¥: é‡å¡‘å›åŸå§‹å½¢çŠ¶
    # (B*n_heads, d_per_head, Lq) â†’ (B, Lq, n_heads*d_per_head)
    output = output.view(N_, M_*D_, Lq_)
    output = output.transpose(1, 2).contiguous()
    # æœ€ç»ˆ: (B, Lq, d_model)
```

**æ•°å­¦è¡¨ç¤º**:

$$\text{output} = \sum_{h=1}^{n_h} \sum_{l=1}^{n_l} \sum_{p=1}^{n_p} \alpha_{h,l,p} \cdot v_{h,l,p}$$

### 7.3 å…·ä½“æ•°å€¼ç¤ºä¾‹

```
å‡è®¾æŸä¸ªæŸ¥è¯¢åªæœ‰2ä¸ªé‡‡æ ·ç‚¹:

é‡‡æ ·ç‚¹1:
  ç‰¹å¾å€¼: [0.5, 0.3, 0.2]
  æƒé‡: 0.7

é‡‡æ ·ç‚¹2:
  ç‰¹å¾å€¼: [0.1, 0.4, 0.6]
  æƒé‡: 0.3

åŠ æƒèåˆ:
  output = 0.7 * [0.5, 0.3, 0.2] + 0.3 * [0.1, 0.4, 0.6]
         = [0.35, 0.21, 0.14] + [0.03, 0.12, 0.18]
         = [0.38, 0.33, 0.32]
```


---

## 8. å®Œæ•´æµç¨‹æ€»ç»“

### 8.1 é‡‡æ ·ç‚¹è·å–çš„å®Œæ•´è¿‡ç¨‹

```
è¾“å…¥: æŸ¥è¯¢å‘é‡ q (bs, 300, 256)
      å‚è€ƒç‚¹ p_ref (bs, 300, 4, 2)
      ç‰¹å¾å›¾ feature_maps (bs, âˆ‘H*W, 256)
  â”‚
  â–¼
ç¬¬1æ­¥: è®¡ç®—é‡‡æ ·åç§» Î”p
  â”‚ Î”p = Linear_offset(q)
  â”‚ å½¢çŠ¶: (bs, 300, 8, 4, 4, 2)
  â”‚ å«ä¹‰: 8ä¸ªå¤´ Ã— 4ä¸ªå±‚ Ã— 4ä¸ªç‚¹ Ã— 2ä¸ªåæ ‡
  â”‚
  â–¼
ç¬¬2æ­¥: è®¡ç®—æ³¨æ„åŠ›æƒé‡ Î±
  â”‚ Î± = softmax(Linear_attn(q))
  â”‚ å½¢çŠ¶: (bs, 300, 8, 4, 4)
  â”‚ å«ä¹‰: 8ä¸ªå¤´ Ã— 4ä¸ªå±‚ Ã— 4ä¸ªç‚¹
  â”‚
  â–¼
ç¬¬3æ­¥: è®¡ç®—é‡‡æ ·ä½ç½® p_sample
  â”‚ p_sample = p_ref + Î”p / offset_normalizer
  â”‚ å½¢çŠ¶: (bs, 300, 8, 4, 4, 2)
  â”‚ èŒƒå›´: [0, 1]
  â”‚
  â–¼
ç¬¬4æ­¥: åŒçº¿æ€§æ’å€¼é‡‡æ ·
  â”‚ v_sample = bilinear_interp(feature_maps, p_sample)
  â”‚ å½¢çŠ¶: (bs, 300, 8, 4, 4, 32)
  â”‚ å«ä¹‰: ä»128ä¸ªé‡‡æ ·ç‚¹è·å–ç‰¹å¾å€¼
  â”‚
  â–¼
ç¬¬5æ­¥: åŠ æƒèåˆ
  â”‚ output = âˆ‘âˆ‘ Î± * v_sample
  â”‚ å½¢çŠ¶: (bs, 300, 256)
  â”‚
  â–¼
è¾“å‡º: æœ€ç»ˆç‰¹å¾ (bs, 300, 256)
```

### 8.2 æ•°æ®æµåŠ¨å›¾

```
æŸ¥è¯¢å‘é‡ (bs, 300, 256)
  â”‚
  â”œâ”€â†’ Linear_offset â”€â†’ é‡‡æ ·åç§» (bs, 300, 256)
  â”‚                        â”‚
  â”‚                        â”œâ”€ reshape â”€â†’ (bs, 300, 8, 4, 4, 2)
  â”‚                        â”‚
  â”‚                        â”œâ”€ + å‚è€ƒç‚¹ â”€â†’ é‡‡æ ·ä½ç½® (bs, 300, 8, 4, 4, 2)
  â”‚                        â”‚
  â”‚                        â”œâ”€ bilinear_interp â”€â†’ é‡‡æ ·ç‰¹å¾ (bs, 300, 8, 4, 4, 32)
  â”‚                        â”‚
  â”‚                        â””â”€ Ã— æ³¨æ„åŠ›æƒé‡ â”€â†’ åŠ æƒç‰¹å¾
  â”‚                                              â”‚
  â”‚                                              â””â”€ sum â”€â†’ è¾“å‡º (bs, 300, 256)
  â”‚
  â””â”€â†’ Linear_attn â”€â†’ æ³¨æ„åŠ›æƒé‡ (bs, 300, 128)
                         â”‚
                         â”œâ”€ reshape â”€â†’ (bs, 300, 8, 16)
                         â”‚
                         â”œâ”€ softmax â”€â†’ (bs, 300, 8, 16)
                         â”‚
                         â””â”€ reshape â”€â†’ (bs, 300, 8, 4, 4)
```

---

## 9. é«˜ä¸­ç”Ÿå­¦ä¹ æŒ‡å—

### 9.1 ä¸‰å¥è¯æ€»ç»“

1. **é‡‡æ ·åç§»**: ä»å‚è€ƒç‚¹åˆ°é‡‡æ ·ç‚¹çš„ç›¸å¯¹ä½ç§»ï¼Œç”±æŸ¥è¯¢å‘é‡é€šè¿‡çº¿æ€§å±‚è®¡ç®—
2. **æ³¨æ„åŠ›æƒé‡**: æ¯ä¸ªé‡‡æ ·ç‚¹çš„é‡è¦æ€§ç³»æ•°ï¼Œé€šè¿‡softmaxä¿è¯æ€»å’Œä¸º1
3. **é‡‡æ ·ç‚¹**: å‚è€ƒç‚¹åŠ ä¸Šé‡‡æ ·åç§»ï¼Œç”¨äºä»ç‰¹å¾å›¾ä¸Šæå–ç‰¹å¾å€¼

### 9.2 å…³é”®æ¦‚å¿µé€Ÿè®°

```
é‡‡æ ·åç§» Î”p:
  - è¾“å…¥: æŸ¥è¯¢å‘é‡ (256ç»´)
  - è¾“å‡º: é‡‡æ ·åç§» (8Ã—4Ã—4Ã—2 = 256ç»´)
  - ä½œç”¨: å‘Šè¯‰æ¨¡å‹åœ¨å‚è€ƒç‚¹å‘¨å›´çš„å“ªé‡Œé‡‡æ ·

æ³¨æ„åŠ›æƒé‡ Î±:
  - è¾“å…¥: æŸ¥è¯¢å‘é‡ (256ç»´)
  - è¾“å‡º: æ³¨æ„åŠ›æƒé‡ (8Ã—4Ã—4 = 128ç»´)
  - ä½œç”¨: å†³å®šæ¯ä¸ªé‡‡æ ·ç‚¹çš„é‡è¦æ€§

é‡‡æ ·ä½ç½® p_sample:
  - è®¡ç®—: p_ref + Î”p / offset_normalizer
  - èŒƒå›´: [0, 1]
  - ä½œç”¨: æŒ‡å®šåœ¨ç‰¹å¾å›¾ä¸Šçš„é‡‡æ ·ä½ç½®

åŒçº¿æ€§æ’å€¼:
  - è¾“å…¥: é‡‡æ ·ä½ç½® (æµ®ç‚¹åæ ‡)
  - è¾“å‡º: ç‰¹å¾å€¼ (ä»å‘¨å›´4ä¸ªåƒç´ æ’å€¼å¾—åˆ°)
  - ä½œç”¨: å¤„ç†éæ•´æ•°åæ ‡

åŠ æƒèåˆ:
  - è¾“å…¥: 128ä¸ªé‡‡æ ·ç‰¹å¾ + 128ä¸ªæƒé‡
  - è¾“å‡º: æœ€ç»ˆç‰¹å¾ (256ç»´)
  - ä½œç”¨: èåˆæ‰€æœ‰é‡‡æ ·ç‚¹çš„ä¿¡æ¯
```

### 9.3 å¸¸è§é—®é¢˜è§£ç­”

**Q1: ä¸ºä»€ä¹ˆéœ€è¦é‡‡æ ·åç§»ï¼Ÿ**

A: å‚è€ƒç‚¹æ˜¯å›ºå®šçš„ï¼Œä½†æˆ‘ä»¬éœ€è¦åœ¨å‚è€ƒç‚¹å‘¨å›´é‡‡æ ·ã€‚é‡‡æ ·åç§»å‘Šè¯‰æ¨¡å‹åœ¨å“ªäº›ä½ç½®é‡‡æ ·ï¼Œè¿™æ ·æ¨¡å‹å¯ä»¥å­¦åˆ°æœ€ä¼˜çš„é‡‡æ ·ç­–ç•¥ã€‚

**Q2: ä¸ºä»€ä¹ˆè¦ç”¨æ³¨æ„åŠ›æƒé‡ï¼Ÿ**

A: 128ä¸ªé‡‡æ ·ç‚¹ä¸­ï¼Œæœ‰äº›æ›´é‡è¦ï¼Œæœ‰äº›ä¸é‡è¦ã€‚æ³¨æ„åŠ›æƒé‡è®©æ¨¡å‹å­¦ä¼šç»™é‡è¦çš„é‡‡æ ·ç‚¹åˆ†é…æ›´é«˜çš„æƒé‡ã€‚

**Q3: ä¸ºä»€ä¹ˆéœ€è¦åŒçº¿æ€§æ’å€¼ï¼Ÿ**

A: é‡‡æ ·ä½ç½®å¯èƒ½ä¸æ˜¯æ•´æ•°åæ ‡ï¼ˆå¦‚0.5, 0.7ï¼‰ï¼Œä½†ç‰¹å¾å›¾åªæœ‰æ•´æ•°åæ ‡çš„åƒç´ ã€‚åŒçº¿æ€§æ’å€¼é€šè¿‡å‘¨å›´4ä¸ªåƒç´ çš„åŠ æƒå¹³å‡æ¥å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚

**Q4: é‡‡æ ·ç‚¹å’Œå‚è€ƒç‚¹æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

A:
- å‚è€ƒç‚¹: ä¸€ä¸ªå›ºå®šçš„ä½ç½®ï¼Œæ˜¯é‡‡æ ·çš„ä¸­å¿ƒ
- é‡‡æ ·ç‚¹: å‚è€ƒç‚¹å‘¨å›´çš„å¤šä¸ªä½ç½®ï¼Œå®é™…é‡‡æ ·çš„åœ°æ–¹

**Q5: ä¸ºä»€ä¹ˆæœ‰8ä¸ªå¤´ï¼Ÿ**

A: 8ä¸ªå¤´å¯¹åº”8ä¸ªä¸åŒçš„æ–¹å‘ï¼Œè®©æ¨¡å‹å¯ä»¥ä»å¤šä¸ªè§’åº¦è§‚å¯Ÿå‚è€ƒç‚¹å‘¨å›´çš„ä¿¡æ¯ã€‚

### 9.4 è®°å¿†æŠ€å·§

```
é‡‡æ ·ç‚¹è·å–çš„5ä¸ªæ­¥éª¤:

1ï¸âƒ£ è®¡ç®—åç§» (Offset)
   æŸ¥è¯¢ â†’ Linear â†’ åç§»

2ï¸âƒ£ è®¡ç®—æƒé‡ (Weight)
   æŸ¥è¯¢ â†’ Linear â†’ Softmax â†’ æƒé‡

3ï¸âƒ£ è®¡ç®—ä½ç½® (Location)
   å‚è€ƒç‚¹ + åç§» = é‡‡æ ·ä½ç½®

4ï¸âƒ£ åŒçº¿æ€§æ’å€¼ (Interpolation)
   é‡‡æ ·ä½ç½® â†’ ç‰¹å¾å€¼

5ï¸âƒ£ åŠ æƒèåˆ (Aggregation)
   ç‰¹å¾å€¼ Ã— æƒé‡ = æœ€ç»ˆè¾“å‡º

è®°ä½: O-W-L-I-A (Offset-Weight-Location-Interpolation-Aggregation)
```

### 9.5 æ•°å€¼å¯¹åº”å…³ç³»

```
å‚æ•°è®¾ç½®:
  n_heads = 8        (8ä¸ªæ³¨æ„åŠ›å¤´)
  n_levels = 4       (4ä¸ªç‰¹å¾å±‚)
  n_points = 4       (æ¯å±‚4ä¸ªé‡‡æ ·ç‚¹)
  d_model = 256      (ç‰¹å¾ç»´åº¦)

é‡‡æ ·åç§»ç»´åº¦:
  è¾“å…¥: (bs, 300, 256)
  è¾“å‡º: (bs, 300, 8Ã—4Ã—4Ã—2) = (bs, 300, 256)

æ³¨æ„åŠ›æƒé‡ç»´åº¦:
  è¾“å…¥: (bs, 300, 256)
  è¾“å‡º: (bs, 300, 8Ã—4Ã—4) = (bs, 300, 128)

é‡‡æ ·ç‚¹æ€»æ•°:
  8 Ã— 4 Ã— 4 = 128 ä¸ªé‡‡æ ·ç‚¹

æ¯ä¸ªæŸ¥è¯¢çš„é‡‡æ ·ç‚¹:
  128 ä¸ªé‡‡æ ·ç‚¹ Ã— 32ç»´ç‰¹å¾ = 4096ç»´ä¿¡æ¯
  é€šè¿‡åŠ æƒèåˆ â†’ 256ç»´è¾“å‡º
```

---

## 10. ä¸å‚è€ƒç‚¹çš„å…³ç³»

### 10.1 å‚è€ƒç‚¹ vs é‡‡æ ·ç‚¹

```
å‚è€ƒç‚¹ (Reference Point):
  - æ•°é‡: 19891ä¸ª (Encoder) æˆ– 300ä¸ª (Decoder)
  - ä½œç”¨: é‡‡æ ·çš„ä¸­å¿ƒä½ç½®
  - æ¥æº: ç‰¹å¾å›¾ç½‘æ ¼ (Encoder) æˆ–å­¦ä¹ å‚æ•° (Decoder)
  - å›ºå®šæ€§: åœ¨ä¸€ä¸ªAttentionå±‚å†…å›ºå®š

é‡‡æ ·ç‚¹ (Sampling Point):
  - æ•°é‡: 128ä¸ª (æ¯ä¸ªæŸ¥è¯¢)
  - ä½œç”¨: å®é™…é‡‡æ ·çš„ä½ç½®
  - æ¥æº: å‚è€ƒç‚¹ + é‡‡æ ·åç§»
  - å¯å˜æ€§: æ ¹æ®æŸ¥è¯¢å‘é‡åŠ¨æ€è®¡ç®—

å…³ç³»:
  é‡‡æ ·ç‚¹ = å‚è€ƒç‚¹ + é‡‡æ ·åç§»

  å‚è€ƒç‚¹æ˜¯"ä¸­å¿ƒ"ï¼Œé‡‡æ ·ç‚¹æ˜¯"å‘¨å›´"
```

### 10.2 å®Œæ•´çš„ä¿¡æ¯æµ

```
åŸå§‹å›¾åƒ (800Ã—1200)
  â”‚
  â–¼
Backboneæå–ç‰¹å¾
  â”‚
  â”œâ”€ Level 0: 100Ã—150 ç‰¹å¾å›¾
  â”œâ”€ Level 1: 50Ã—75 ç‰¹å¾å›¾
  â”œâ”€ Level 2: 25Ã—37 ç‰¹å¾å›¾
  â””â”€ Level 3: 12Ã—18 ç‰¹å¾å›¾
  â”‚
  â–¼
Encoderå¤„ç†
  â”‚
  â”œâ”€ å‚è€ƒç‚¹: 19891ä¸ª (æ‰€æœ‰ç‰¹å¾åƒç´ )
  â”œâ”€ é‡‡æ ·ç‚¹: 19891 Ã— 128 = 254ä¸‡ä¸ª
  â””â”€ è¾“å‡º: Memory (bs, 19891, 256)
  â”‚
  â–¼
Decoderå¤„ç† (6å±‚)
  â”‚
  â”œâ”€ å‚è€ƒç‚¹: 300ä¸ª (æŸ¥è¯¢)
  â”œâ”€ é‡‡æ ·ç‚¹: 300 Ã— 128 = 3.84ä¸‡ä¸ª
  â”œâ”€ æ¯å±‚éƒ½æ›´æ–°å‚è€ƒç‚¹
  â””â”€ è¾“å‡º: æœ€ç»ˆé¢„æµ‹ (bs, 300, num_classes)
```

---

## 11. å®è·µå»ºè®®

### 11.1 è°ƒè¯•é‡‡æ ·ç‚¹çš„æ–¹æ³•

```python
# 1. æ‰“å°é‡‡æ ·åç§»çš„ç»Ÿè®¡ä¿¡æ¯
def debug_sampling_offsets(sampling_offsets):
    print(f"é‡‡æ ·åç§»å½¢çŠ¶: {sampling_offsets.shape}")
    print(f"  æœ€å°å€¼: {sampling_offsets.min():.4f}")
    print(f"  æœ€å¤§å€¼: {sampling_offsets.max():.4f}")
    print(f"  å¹³å‡å€¼: {sampling_offsets.mean():.4f}")
    print(f"  æ ‡å‡†å·®: {sampling_offsets.std():.4f}")

# 2. æ‰“å°æ³¨æ„åŠ›æƒé‡çš„åˆ†å¸ƒ
def debug_attention_weights(attention_weights):
    print(f"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention_weights.shape}")
    print(f"  æœ€å°å€¼: {attention_weights.min():.4f}")
    print(f"  æœ€å¤§å€¼: {attention_weights.max():.4f}")
    print(f"  å¹³å‡å€¼: {attention_weights.mean():.4f}")
    # æ£€æŸ¥æ˜¯å¦æœ‰æƒé‡ä¸º0
    zero_count = (attention_weights == 0).sum()
    print(f"  é›¶æƒé‡æ•°: {zero_count}")

# 3. å¯è§†åŒ–é‡‡æ ·ç‚¹ä½ç½®
def visualize_sampling_points(reference_points, sampling_offsets,
                              offset_normalizer, image_size):
    """
    å¯è§†åŒ–å‚è€ƒç‚¹å’Œé‡‡æ ·ç‚¹çš„ä½ç½®
    """
    import matplotlib.pyplot as plt

    H, W = image_size

    # è®¡ç®—é‡‡æ ·ä½ç½®
    sampling_locations = reference_points + sampling_offsets / offset_normalizer

    fig, ax = plt.subplots(figsize=(12, 8))

    # ç»˜åˆ¶å‚è€ƒç‚¹
    ref_x = reference_points[0, :, 0].cpu().numpy() * W
    ref_y = reference_points[0, :, 1].cpu().numpy() * H
    ax.scatter(ref_x, ref_y, c='red', s=50, label='Reference Points', alpha=0.6)

    # ç»˜åˆ¶é‡‡æ ·ç‚¹ (åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªæŸ¥è¯¢çš„é‡‡æ ·ç‚¹)
    sample_x = sampling_locations[0, :, 0].cpu().numpy() * W
    sample_y = sampling_locations[0, :, 1].cpu().numpy() * H
    ax.scatter(sample_x, sample_y, c='blue', s=20, label='Sampling Points', alpha=0.3)

    # è¿æ¥å‚è€ƒç‚¹å’Œé‡‡æ ·ç‚¹
    for i in range(len(ref_x)):
        ax.plot([ref_x[i], sample_x[i]], [ref_y[i], sample_y[i]],
                'g-', alpha=0.1, linewidth=0.5)

    ax.set_xlim(0, W)
    ax.set_ylim(H, 0)
    ax.set_aspect('equal')
    ax.legend()
    ax.set_title('Reference Points and Sampling Points')

    return fig
```

### 11.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

```
1. é‡‡æ ·åç§»çš„åˆå§‹åŒ–å¾ˆé‡è¦
   - åœ†å½¢åˆå§‹åŒ–èƒ½è®©é‡‡æ ·ç‚¹å‡åŒ€åˆ†å¸ƒ
   - è·ç¦»é€’å¢èƒ½æ•æ‰å¤šå°ºåº¦ä¿¡æ¯

2. æ³¨æ„åŠ›æƒé‡çš„softmaxå¾ˆå…³é”®
   - ç¡®ä¿æƒé‡å’Œä¸º1
   - é¿å…æƒé‡è¿‡äºé›†ä¸­æˆ–åˆ†æ•£

3. åŒçº¿æ€§æ’å€¼çš„ç²¾åº¦
   - ä½¿ç”¨align_corners=Falseæ›´ç¨³å®š
   - padding_mode='zeros'å¤„ç†è¾¹ç•Œ

4. åŠ æƒèåˆçš„æ•ˆç‡
   - ä½¿ç”¨å‘é‡åŒ–æ“ä½œè€Œä¸æ˜¯å¾ªç¯
   - å……åˆ†åˆ©ç”¨GPUå¹¶è¡Œè®¡ç®—
```


---

## æ€»ç»“

### é‡‡æ ·ç‚¹è·å–çš„æ ¸å¿ƒè¦ç‚¹

**é‡‡æ ·ç‚¹(Sampling Points)** æ˜¯Deformable DETRä¸­æœ€å…³é”®çš„åˆ›æ–°ï¼Œå®ƒè§£å†³äº†æ ‡å‡†Transformerä¸­çš„ä¸¤ä¸ªé—®é¢˜ï¼š

1. **è®¡ç®—æ•ˆç‡**: ä¸éœ€è¦è®¡ç®—æ‰€æœ‰åƒç´ é—´çš„ç›¸ä¼¼åº¦ï¼Œåªåœ¨å‚è€ƒç‚¹å‘¨å›´é‡‡æ ·
2. **çµæ´»æ€§**: é‡‡æ ·ä½ç½®ç”±æ¨¡å‹å­¦ä¹ ï¼Œèƒ½è‡ªé€‚åº”è°ƒæ•´

### é‡‡æ ·ç‚¹çš„5ä¸ªå…³é”®æ­¥éª¤

```
1. é‡‡æ ·åç§» (Offset)
   â”œâ”€ è¾“å…¥: æŸ¥è¯¢å‘é‡ (256ç»´)
   â”œâ”€ è®¡ç®—: Linearå±‚ (256 â†’ 256)
   â””â”€ è¾“å‡º: é‡‡æ ·åç§» (8Ã—4Ã—4Ã—2)

2. æ³¨æ„åŠ›æƒé‡ (Weight)
   â”œâ”€ è¾“å…¥: æŸ¥è¯¢å‘é‡ (256ç»´)
   â”œâ”€ è®¡ç®—: Linear + Softmax (256 â†’ 128)
   â””â”€ è¾“å‡º: æ³¨æ„åŠ›æƒé‡ (8Ã—4Ã—4)

3. é‡‡æ ·ä½ç½® (Location)
   â”œâ”€ è¾“å…¥: å‚è€ƒç‚¹ + é‡‡æ ·åç§»
   â”œâ”€ è®¡ç®—: p_ref + Î”p / offset_normalizer
   â””â”€ è¾“å‡º: é‡‡æ ·ä½ç½® (8Ã—4Ã—4Ã—2)

4. åŒçº¿æ€§æ’å€¼ (Interpolation)
   â”œâ”€ è¾“å…¥: é‡‡æ ·ä½ç½® (æµ®ç‚¹åæ ‡)
   â”œâ”€ è®¡ç®—: å‘¨å›´4ä¸ªåƒç´ çš„åŠ æƒå¹³å‡
   â””â”€ è¾“å‡º: é‡‡æ ·ç‰¹å¾ (8Ã—4Ã—4Ã—32)

5. åŠ æƒèåˆ (Aggregation)
   â”œâ”€ è¾“å…¥: é‡‡æ ·ç‰¹å¾ + æ³¨æ„åŠ›æƒé‡
   â”œâ”€ è®¡ç®—: âˆ‘âˆ‘ Î± * v_sample
   â””â”€ è¾“å‡º: æœ€ç»ˆç‰¹å¾ (256ç»´)
```

### é«˜ä¸­ç”Ÿå¿…é¡»ç†è§£çš„3ä¸ªæ¦‚å¿µ

1. **é‡‡æ ·åç§» = ç›¸å¯¹ä½ç§»**
   - å‘Šè¯‰æ¨¡å‹åœ¨å‚è€ƒç‚¹å‘¨å›´çš„å“ªé‡Œé‡‡æ ·
   - ç”±æŸ¥è¯¢å‘é‡é€šè¿‡çº¿æ€§å±‚è®¡ç®—
   - åˆæœŸåˆå§‹åŒ–ä¸ºåœ†å½¢åˆ†å¸ƒ

2. **æ³¨æ„åŠ›æƒé‡ = é‡è¦æ€§ç³»æ•°**
   - å†³å®šæ¯ä¸ªé‡‡æ ·ç‚¹å¯¹æœ€ç»ˆç»“æœçš„è´¡çŒ®
   - é€šè¿‡softmaxä¿è¯æ€»å’Œä¸º1
   - è®©æ¨¡å‹å­¦ä¼šå…³æ³¨é‡è¦çš„é‡‡æ ·ç‚¹

3. **åŒçº¿æ€§æ’å€¼ = æµ®ç‚¹åæ ‡å¤„ç†**
   - é‡‡æ ·ä½ç½®å¯èƒ½ä¸æ˜¯æ•´æ•°åæ ‡
   - ç”¨å‘¨å›´4ä¸ªåƒç´ çš„åŠ æƒå¹³å‡å¤„ç†
   - ä¿è¯é‡‡æ ·çš„è¿ç»­æ€§å’Œå¯å¾®æ€§

### ä¸å‚è€ƒç‚¹çš„å…³ç³»

```
å‚è€ƒç‚¹ (Reference Point)
  â†“
  æ˜¯é‡‡æ ·çš„ä¸­å¿ƒä½ç½®
  â†“
å‚è€ƒç‚¹ + é‡‡æ ·åç§» = é‡‡æ ·ç‚¹ (Sampling Point)
  â†“
  æ˜¯å®é™…é‡‡æ ·çš„ä½ç½®
  â†“
ä»é‡‡æ ·ç‚¹æå–ç‰¹å¾å€¼
  â†“
ç”¨æ³¨æ„åŠ›æƒé‡åŠ æƒèåˆ
  â†“
å¾—åˆ°æœ€ç»ˆç‰¹å¾
```

### æ€§èƒ½å¯¹æ¯”

```
æ ‡å‡†Attention:
  - è®¡ç®—æ‰€æœ‰åƒç´ é—´çš„ç›¸ä¼¼åº¦
  - å¤æ‚åº¦: O(NÂ²)ï¼ŒN = 19891
  - è®¡ç®—é‡: 3.95äº¿æ¬¡

Deformable Attention:
  - åªåœ¨å‚è€ƒç‚¹å‘¨å›´é‡‡æ ·
  - å¤æ‚åº¦: O(N Ã— K)ï¼ŒK = 128
  - è®¡ç®—é‡: 254ä¸‡æ¬¡
  - åŠ é€Ÿ: 155å€ï¼
```

### å­¦ä¹ è·¯çº¿å›¾

```
åˆçº§ (ç†è§£åŸºç¡€)
  â”œâ”€ é‡‡æ ·åç§»æ˜¯ä»€ä¹ˆ
  â”œâ”€ æ³¨æ„åŠ›æƒé‡æ˜¯ä»€ä¹ˆ
  â””â”€ é‡‡æ ·ç‚¹æ€ä¹ˆè®¡ç®—

ä¸­çº§ (ç†è§£ç»†èŠ‚)
  â”œâ”€ é‡‡æ ·åç§»çš„åˆå§‹åŒ–
  â”œâ”€ Softmaxçš„ä½œç”¨
  â”œâ”€ åŒçº¿æ€§æ’å€¼çš„åŸç†
  â””â”€ åŠ æƒèåˆçš„è®¡ç®—

é«˜çº§ (ç†è§£ä¼˜åŒ–)
  â”œâ”€ ä¸ºä»€ä¹ˆè¿™æ ·åˆå§‹åŒ–
  â”œâ”€ å¦‚ä½•è°ƒè¯•é‡‡æ ·ç‚¹
  â”œâ”€ å¦‚ä½•ä¼˜åŒ–æ€§èƒ½
  â””â”€ å¦‚ä½•æ‰©å±•åˆ°å…¶ä»–ä»»åŠ¡
```

---

## å‚è€ƒèµ„æº

### åŸå§‹è®ºæ–‡
- Deformable DETR: Deformable Transformers for End-to-End Object Detection
- è®ºæ–‡é“¾æ¥: https://arxiv.org/abs/2010.04159

### ä»£ç ä½ç½®
- é‡‡æ ·åç§»åˆå§‹åŒ–: `models/ops/modules/ms_deform_attn.py` ç¬¬62-72è¡Œ
- é‡‡æ ·åç§»è®¡ç®—: `models/ops/modules/ms_deform_attn.py` ç¬¬93-100è¡Œ
- æ³¨æ„åŠ›æƒé‡è®¡ç®—: `models/ops/modules/ms_deform_attn.py` ç¬¬99-100è¡Œ
- é‡‡æ ·ä½ç½®è®¡ç®—: `models/ops/modules/ms_deform_attn.py` ç¬¬102-108è¡Œ
- åŒçº¿æ€§æ’å€¼: `models/ops/functions/ms_deform_attn_func.py` ç¬¬41-57è¡Œ
- åŠ æƒèåˆ: `models/ops/functions/ms_deform_attn_func.py` ç¬¬58-61è¡Œ

### å…³é”®æ¦‚å¿µç´¢å¼•
- é‡‡æ ·åç§» (Sampling Offsets): ç¬¬3èŠ‚
- æ³¨æ„åŠ›æƒé‡ (Attention Weights): ç¬¬4èŠ‚
- é‡‡æ ·ä½ç½® (Sampling Locations): ç¬¬5èŠ‚
- åŒçº¿æ€§æ’å€¼ (Bilinear Interpolation): ç¬¬6èŠ‚
- åŠ æƒèåˆ (Weighted Aggregation): ç¬¬7èŠ‚
- å®Œæ•´æµç¨‹ (Complete Pipeline): ç¬¬8èŠ‚
- é«˜ä¸­ç”ŸæŒ‡å— (High School Guide): ç¬¬9èŠ‚

---

## å¸¸è§é—®é¢˜é€ŸæŸ¥è¡¨

| é—®é¢˜ | ç­”æ¡ˆ | ä½ç½® |
|------|------|------|
| é‡‡æ ·åç§»æ˜¯ä»€ä¹ˆ? | ä»å‚è€ƒç‚¹åˆ°é‡‡æ ·ç‚¹çš„ç›¸å¯¹ä½ç§» | 3.1 |
| ä¸ºä»€ä¹ˆéœ€è¦é‡‡æ ·åç§»? | è®©æ¨¡å‹å­¦åˆ°æœ€ä¼˜çš„é‡‡æ ·ç­–ç•¥ | 9.3 Q1 |
| æ³¨æ„åŠ›æƒé‡æ€ä¹ˆè®¡ç®—? | Linear + Softmax | 4.2 |
| ä¸ºä»€ä¹ˆè¦ç”¨softmax? | ä¿è¯æƒé‡å’Œä¸º1ï¼Œè¡¨ç¤ºé‡è¦æ€§ | 4.3 |
| é‡‡æ ·ä½ç½®æ€ä¹ˆè®¡ç®—? | p_ref + Î”p / offset_normalizer | 5.1 |
| ä¸ºä»€ä¹ˆéœ€è¦åŒçº¿æ€§æ’å€¼? | å¤„ç†éæ•´æ•°åæ ‡ | 9.3 Q3 |
| é‡‡æ ·ç‚¹å’Œå‚è€ƒç‚¹çš„åŒºåˆ«? | å‚è€ƒç‚¹æ˜¯ä¸­å¿ƒï¼Œé‡‡æ ·ç‚¹æ˜¯å‘¨å›´ | 9.3 Q4 |
| ä¸ºä»€ä¹ˆæœ‰8ä¸ªå¤´? | 8ä¸ªä¸åŒæ–¹å‘ï¼Œå…¨é¢è¦†ç›– | 9.3 Q5 |
| æ€»é‡‡æ ·ç‚¹æ•°æ˜¯å¤šå°‘? | 8 Ã— 4 Ã— 4 = 128ä¸ª | 2.2 |
| åŠ é€Ÿå€æ•°æ˜¯å¤šå°‘? | 155å€ | æ€»ç»“ |

---

**æ–‡æ¡£å®Œæˆï¼** ğŸ‰

è¿™ä»½æ–‡æ¡£è¯¦ç»†è§£é‡Šäº†Deformable DETRä¸­é‡‡æ ·ç‚¹çš„è·å–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- âœ… é‡‡æ ·åç§»çš„è®¡ç®—å’Œåˆå§‹åŒ–
- âœ… æ³¨æ„åŠ›æƒé‡çš„è®¡ç®—
- âœ… é‡‡æ ·ä½ç½®çš„å…¬å¼
- âœ… åŒçº¿æ€§æ’å€¼çš„åŸç†
- âœ… åŠ æƒèåˆçš„è¿‡ç¨‹
- âœ… å®Œæ•´çš„æµç¨‹æ€»ç»“
- âœ… é«˜ä¸­ç”Ÿå‹å¥½çš„å­¦ä¹ æŒ‡å—
- âœ… å®è·µè°ƒè¯•å»ºè®®

æ‰€æœ‰å†…å®¹éƒ½ç”¨ä»£ç ã€æ•°å­¦å…¬å¼å’Œå›¾ä¾‹ç»“åˆï¼Œè®©é«˜ä¸­ç”Ÿèƒ½å¤Ÿç†è§£ï¼